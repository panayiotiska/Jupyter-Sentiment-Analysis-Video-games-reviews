{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr><td>\n",
    "         <img alt=\"start\" src=\"figures/button_unable_previous.jpg\" width= 70% height= 70%>\n",
    "    </td><td>\n",
    "        <a href=\"https://nbviewer.jupyter.org/github/panayiotiska/Jupyter-Sentiment-Analysis-Video-games-reviews/blob/master/Index.ipynb\">\n",
    "         <img alt=\"start\" src=\"figures/button_table-of-contents.jpg\" width= 70% height= 70%>\n",
    "    </td><td>\n",
    "         <a href=\"https://nbviewer.jupyter.org/github/panayiotiska/Jupyter-Sentiment-Analysis-Video-games-reviews/blob/master/[Data_Exploration]Data_Lookup.ipynb\">\n",
    "         <img alt=\"start\" src=\"figures/button_next.jpg\" width= 70% height= 70%>\n",
    "    </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1>Introduction</h1> </center>\n",
    "<center> <h1>Natural Language Processing and Sentiment Analysis</h1> </center>\n",
    "<center> <h2>Panayiotis Kattides</h2> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "Sentiment analysis or opinion mining is one of the major tasks of NLP (Natural Language Processing). This notebook illustrates a sentiment analysis approach to extract sentiments associated with polarities of positive, neutral or negative for specific subjects from a dataset. The essential issues in sentiment analysis are to identify how sentiments are expressed in texts and whether the expressions indicate positive or negative opinions toward the subject. Data used in this study are online product reviews of video games collected from Amazon.com, the world's largest online marketplace. Customers are often satisfied or dissatisfied and accordingly reviewing the products. The main goal is to build a system that does better classification of those reviews than current text sentiment analysis tools, as the structure of reviews is not same as regular text. The two algorithms used for classification are Support Vector Machine and Naive Bayes working together with several python libraries such as NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "Sentiment analysis is contextual mining of text which identifies and extracts subjective information in source material. It is the most common text classification tool that analyses an incoming message with the help of machine learning. Machine learning for NLP and text analytics involves a set of statistical techniques for identifying parts of speech, entities, sentiment, and other aspects of text. Text data requires a special approach to machine learning. This is because text data can have hundreds of thousands of dimensions (words and phrases) but tends to be very sparse. For example, the English language has around 100,000 words in common use. But any given review only contains a few of them.\n",
    "The particular problem being examined includes the rating of each review together with the review text. The rating plays the role of the label that is the category it belongs. This fact makes this probelm a supervised machine learning problem. The reviews together with their ratings will be used in order to “train” a statistical model, which is then given un-labeled text to analyze and classify. Some of most popular supervised NLP machine learning algorithms are those to be used:\n",
    "- Naive Bayes Classifier\n",
    "- Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier\n",
    "\n",
    "In probability theory and statistics, Bayes theorem describes the probability of an event, based on prior knowledge of conditions that might be related to the event. Naive Bayes algorithm is applying Bayes theorem with a strong (naive) assumption, that every feature is independent of the others in order to predict the category of a given sample. It is a probabilistic classifier, therefore will calculate the probability of each category using Bayes theorem, and the category with the highest probability will be the output.\n",
    "\n",
    "### Example:\n",
    "\n",
    "Consider n features to be represented as a vector which in an NLP problem the vector is an array of words:\n",
    "\n",
    "\\begin{equation*}\n",
    "X = (\"This\", \"is\", \"a\", \"review\")\n",
    "\\end{equation*}\n",
    "\n",
    "The probabilities that the Naïve Bayes model assigns to the **k** classes will be as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(Class_k| \"This\", \"is\", \"a\", \"review\")\n",
    "\\end{equation*}\n",
    "\n",
    "Implementing Bayes theorem, we can determine the\n",
    "conditional probability of predicting the class given a feature:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(Class_k|X) = \\frac{P(Class_k)P(X|Class_k)}{P(X)}.\n",
    "\\end{equation*}\n",
    "\n",
    "Τaking into account the three classes which will be used (Positive, Negative, Neutral) and the review vector:\n",
    "\n",
    "- The probability that the review belongs to the positive class: \n",
    "\n",
    "\\begin{equation*}\n",
    "P(Positive|X) = \\frac{P(Positive)*P(This|Positive)*P(is|Positive)*P(a|Positive)*P(review|Positive)}{P(This)*P(is)*P(a)*P(review)}.\n",
    "\\end{equation*}\n",
    "\n",
    "- The probability that the review belongs to the negative class: \n",
    "\n",
    "\\begin{equation*}\n",
    "P(Negative|X) = \\frac{P(Negative)*P(This|Negative)*P(is|Negative)*P(a|Negative)*P(review|Negative)}{P(This)*P(is)*P(a)*P(review)}.\n",
    "\\end{equation*}\n",
    "\n",
    "- The probability that the review belongs to the neutral class: \n",
    "\n",
    "\\begin{equation*}\n",
    "P(Neutral|X) = \\frac{P(Neutral)*P(This|Neutral)*P(is|Neutral)*P(a|Neutral)*P(review|Neutral)}{P(This)*P(is)*P(a)*P(review)}.\n",
    "\\end{equation*}\n",
    "\n",
    "Finally, the review is being classified to the class which outputs the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines are associated with learning algorithms which learn from data to decipher patterns in classification and regression analysis.The SVM is based on the idea that we can separate classes in a multi-dimensional feature space by means of a hyperplane.\n",
    "\n",
    "Showing an example with two classes the aim is to find the hyperplane with the maximum marginal distance. Multiple hyperplanes are being examined for a specific problem and the one with the maximum marginal distance is being chosen.\n",
    "\n",
    "### Example:\n",
    "\n",
    "- As illustrated below, the marginal distance which arises by the hyperplane on the left graph is much higher than the one that arises on the right graph So the hyperplane on the left is considered better. Τhe procedure repeats until the best hyperplane is being found.\n",
    "\n",
    "<img src=\"figures/svm_marginal_distance.png\" width=\"700\" align=\"center\"/>\n",
    "\n",
    "\n",
    "- The support vectors consist of the coordinates of the points the marginal-plane passes through. Support vectors help calculate the marginal distance in order to distinguish the maximum marginal distance.\n",
    "\n",
    "<img src=\"figures/svm_vectors.png\" width=\"400\" align=\"center\"/>\n",
    "\n",
    "- In some problems the classes cannot be seperated using a hyperplane in the form of a straight line as for example the following problem.\n",
    "\n",
    "<img src=\"figures/svm_2dproblem.png\" width=\"400\" align=\"center\"/>\n",
    "\n",
    "- Kernel is a mathematical technique that allows solving implicitly a linear separation problem in a higher dimensional feature. It converts the two-dimensional problem to a multi-dimensional problem in order to be able to divide the classes with a hyper plance as shown.\n",
    "\n",
    "<img src=\"figures/svm_2dsolution.png\" width=\"400\" align=\"center\"/>\n",
    "\n",
    "After the seperation is done, the model is considered trained having in disposal the hyperplanes together with the two support vectors, every new point can be classified acording to its coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://nbviewer.jupyter.org/github/panayiotiska/Jupyter-Sentiment-Analysis-Video-games-reviews/blob/master/[Data_Exploration]Data_Lookup.ipynb\">\n",
    "         <img alt=\"start\" src=\"figures/button_next.jpg\">"
   ]
  }
 ],
 "metadata": {
  "author": "Bibliography management:\\\\texttt{thebibliography",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
