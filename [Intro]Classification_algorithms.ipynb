{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr><td>\n",
    "         <a href=\"https://nbviewer.jupyter.org/github/panayiotiska/Jupyter-Sentiment-Analysis-Video-games-reviews/blob/master/Introduction.ipynb\">\n",
    "         <img alt=\"start\" src=\"figures/button_previous.jpg\" width= 70% height= 70%>\n",
    "    </td><td>\n",
    "        <a href=\"https://nbviewer.jupyter.org/github/panayiotiska/Jupyter-Sentiment-Analysis-Video-games-reviews/blob/master/Index.ipynb\">\n",
    "         <img alt=\"start\" src=\"figures/button_table-of-contents.jpg\" width= 70% height= 70%>\n",
    "    </td><td>\n",
    "         <a href=\"https://nbviewer.jupyter.org/github/panayiotiska/Jupyter-Sentiment-Analysis-Video-games-reviews/blob/master/[Intro]Evaluation_metrics.ipynb\">\n",
    "         <img alt=\"start\" src=\"figures/button_next.jpg\" width= 70% height= 70%>\n",
    "    </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier\n",
    "\n",
    "In probability theory and statistics, Bayes theorem describes the probability of an event, based on prior knowledge of conditions that might be related to the event. Naive Bayes algorithm is applying Bayes theorem with a strong (naive) assumption, that every feature is independent of the others in order to predict the category of a given sample. It is a probabilistic classifier, therefore will calculate the probability of each category using Bayes theorem, and the category with the highest probability will be the output.\n",
    "\n",
    "### Example:\n",
    "\n",
    "Consider n features to be represented as a vector which in an NLP problem the vector is an array of words:\n",
    "\n",
    "\\begin{equation*}\n",
    "X = (\"This\", \"is\", \"a\", \"review\")\n",
    "\\end{equation*}\n",
    "\n",
    "The probabilities that the Naïve Bayes model assigns to the **k** classes will be as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(Class_k| \"This\", \"is\", \"a\", \"review\")\n",
    "\\end{equation*}\n",
    "\n",
    "Implementing Bayes theorem, we can determine the\n",
    "conditional probability of predicting the class given a feature:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(Class_k|X) = \\frac{P(Class_k)P(X|Class_k)}{P(X)}.\n",
    "\\end{equation*}\n",
    "\n",
    "Τaking into account the three classes which will be used (Positive, Negative, Neutral) and the review vector:\n",
    "\n",
    "- The probability that the review belongs to the positive class: \n",
    "\n",
    "\\begin{equation*}\n",
    "P(Positive|X) = \\frac{P(Positive)*P(This|Positive)*P(is|Positive)*P(a|Positive)*P(review|Positive)}{P(This)*P(is)*P(a)*P(review)}.\n",
    "\\end{equation*}\n",
    "\n",
    "- The probability that the review belongs to the negative class: \n",
    "\n",
    "\\begin{equation*}\n",
    "P(Negative|X) = \\frac{P(Negative)*P(This|Negative)*P(is|Negative)*P(a|Negative)*P(review|Negative)}{P(This)*P(is)*P(a)*P(review)}.\n",
    "\\end{equation*}\n",
    "\n",
    "- The probability that the review belongs to the neutral class: \n",
    "\n",
    "\\begin{equation*}\n",
    "P(Neutral|X) = \\frac{P(Neutral)*P(This|Neutral)*P(is|Neutral)*P(a|Neutral)*P(review|Neutral)}{P(This)*P(is)*P(a)*P(review)}.\n",
    "\\end{equation*}\n",
    "\n",
    "Finally, the review is being classified to the class which outputs the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines Classifier\n",
    "\n",
    "Support Vector Machines are associated with learning algorithms which learn from data to decipher patterns in classification and regression analysis.The SVM is based on the idea that we can separate classes in a multi-dimensional feature space by means of a hyperplane.\n",
    "\n",
    "Showing an example with two classes the aim is to find the hyperplane with the maximum marginal distance. Multiple hyperplanes are being examined for a specific problem and the one with the maximum marginal distance is being chosen.\n",
    "\n",
    "### Example:\n",
    "\n",
    "- As illustrated below, the marginal distance which arises by the hyperplane on the left graph is much higher than the one that arises on the right graph So the hyperplane on the left is considered better. Τhe procedure repeats until the best hyperplane is being found.\n",
    "\n",
    "<img src=\"figures/svm_marginal_distance.png\" width=\"700\" align=\"center\"/>\n",
    "\n",
    "\n",
    "- The support vectors consist of the coordinates of the points the marginal-plane passes through. Support vectors help calculate the marginal distance in order to distinguish the maximum marginal distance.\n",
    "\n",
    "<img src=\"figures/svm_vectors.png\" width=\"400\" align=\"center\"/>\n",
    "\n",
    "- In some problems the classes cannot be seperated using a hyperplane in the form of a straight line as for example the following problem.\n",
    "\n",
    "<img src=\"figures/svm_2dproblem.png\" width=\"400\" align=\"center\"/>\n",
    "\n",
    "- Kernel is a mathematical technique that allows solving implicitly a linear separation problem in a higher dimensional feature. It converts the two-dimensional problem to a multi-dimensional problem in order to be able to divide the classes with a hyper plance as shown.\n",
    "\n",
    "<img src=\"figures/svm_2dsolution.png\" width=\"400\" align=\"center\"/>\n",
    "\n",
    "After the seperation is done, the model is considered trained having in disposal the hyperplanes together with the two support vectors, every new point can be classified acording to its coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://nbviewer.jupyter.org/github/panayiotiska/Jupyter-Sentiment-Analysis-Video-games-reviews/blob/master/[Intro]Evaluation_metrics.ipynb\">\n",
    "         <img alt=\"start\" src=\"figures/button_next.jpg\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
