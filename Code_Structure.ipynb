{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr><td>\n",
    "         <a href=\"https://nbviewer.jupyter.org/github/panayiotiska/Jupyter-Sentiment-Analysis-Video-games-reviews/blob/master/[Data_Exploration]Word-Clouds.ipynb\">\n",
    "         <img alt=\"start\" src=\"figures/button_previous.jpg\" width= 70% height= 70%>\n",
    "    </td><td>\n",
    "        <a href=\"https://nbviewer.jupyter.org/github/panayiotiska/Jupyter-Sentiment-Analysis-Video-games-reviews/blob/master/Index.ipynb\">\n",
    "         <img alt=\"start\" src=\"figures/button_table-of-contents.jpg\" width= 70% height= 70%>\n",
    "    </td><td>\n",
    "         <a href=\"https://nbviewer.jupyter.org/github/panayiotiska/Jupyter-Sentiment-Analysis-Video-games-reviews/blob/master/Vectorization.ipynb\">\n",
    "         <img alt=\"start\" src=\"figures/button_next.jpg\" width= 70% height= 70%>\n",
    "    </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic code structure\n",
    "In this notebook the form and code structure of the sentiment analysis part is illustrated and explained in order to better understand the following notebooks.\n",
    "\n",
    "\n",
    "The basic structure consists of the following steps:\n",
    "\n",
    "- Import data from a json file into a pandas dataframe.\n",
    "- Reduce the number of classes to three classes.\n",
    "- Transform the text/corpora to a cleaner version.\n",
    "- Seperate the dataset to training and test set.\n",
    "- Transform text to a numerical form by performing vectorization.\n",
    "- Perform classification, predict and print the results/reports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          reviewText  overall\n",
      "0  Installing the game was a struggle (because of...        1\n",
      "1  If you like rally cars get this game you will ...        4\n",
      "2  1st shipment received a book instead of the ga...        1\n",
      "3  I got this version instead of the PS3 version,...        3\n",
      "4  I had Dirt 2 on Xbox 360 and it was an okay ga...        4\n",
      "________________________________________________________________\n",
      "\n",
      "ratings:  [-1, 1, -1, 0, 1, 1, 1, -1, 1, -1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "\n",
    "#[1] Importing dataset\n",
    "\n",
    "dataset = pd.read_json(r\"C:\\Users\\Panos\\Desktop\\Dissert\\Code\\Sample_Video_Games_5.json\", lines=True, encoding='latin-1')\n",
    "dataset = dataset[['reviewText','overall']]\n",
    "\n",
    "#[2] Reduce number of classes\n",
    "\n",
    "ratings = []\n",
    "for index,entry in enumerate(dataset['overall']):\n",
    "    if entry == 1.0 or entry == 2.0:\n",
    "        ratings.append(-1)\n",
    "    elif entry == 3.0:\n",
    "        ratings.append(0)\n",
    "    elif entry == 4.0 or entry == 5.0:\n",
    "        ratings.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above at first, reads the json file and and stores the data in a pandas(library) dataframe. The dataframe consists of two columns \"reviewText\" and \"overall\" as shown in the print area above. The reviewText column includes the string writen by the customer reviewing an item. The overall column contains an integer with a value from 1 to 5, representing the rating-score left by the customer for the corresponding item.\n",
    "\n",
    "The next step in the code reduces the range of the overall integer value from 5 (1 to 5) to 3 (-1 to 1) by saving the new values in the 'ratings' list. In other words the number of classes is reduced by the following procedure: the ratings rated with 1 or 2 stars are negative (-1), ratings rated with 3 stars are neutral (0) and ratings rated with 4 or 5 stars are positive, as shown below.\n",
    "\n",
    "&#11088; &#8594; Negative (-1)\n",
    "\n",
    "&#11088; &#11088; &#8594; Negative (-1)\n",
    "\n",
    "&#11088; &#11088; &#11088; &#8594; Neutral (0)\n",
    "\n",
    "&#11088; &#11088; &#11088; &#11088; &#8594; Positive (1)\n",
    "\n",
    "&#11088; &#11088; &#11088; &#11088; &#11088; &#8594; Positive (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example\n",
      "\n",
      "Before cleaning:\n",
      "\n",
      "1st shipment received a book instead of the game.2nd shipment got a FAKE one. Game arrived with a wrong key inside on sealed box. I got in contact with codemasters and send them pictures of the DVD and the content. They said nothing they can do its a fake DVD.Returned it good bye.!\n",
      "\n",
      "After Cleaning:\n",
      "\n",
      "st shipment received book instead game nd shipment got fake one game arrived wrong key inside sealed box got contact codemasters send pictures dvd content said nothing fake dvd returned good bye\n"
     ]
    }
   ],
   "source": [
    "#[3] Cleaning the text\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "corpus = []\n",
    "for i in range(0, len(dataset)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['reviewText'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code section, different cleaning/pre-processing techniques are applied in order to make the text more machine-friendly, remove unwanted tokens and match together identical tokens. \n",
    "\n",
    "In this example, all characters that do not belong to the english alphabet (from a to z and A to Z) are being removed. Also, all capital letters are transformed to small letters and stopwords are being removed using the nltk library. Stop-words usually refer to the most common words in a language which do not affect the meaning of a sentence but are mostly \"auxiliary\".\n",
    "\n",
    "In the next notebooks different pre-processing methods will be examined in order to achieve a better final accuracy as this is a critical part for sentiment analysis. Specifically, different stemming methods are being tested and regular expressions(regex) are being experimented in the final section of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[4] Prepare Train and Test Data sets\n",
    "            \n",
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(corpus,ratings,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, the dataset is split to the training and test set in order to be able to later calculate the accuracy and decide whether the model is favorable using the test-set. The test-set is a small part of the dataset left un-trained. In this example the test set consists of the 30% of the entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[5] Encoding\n",
    "\n",
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Test_Y = Encoder.fit_transform(Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[6] Word Vectorization\n",
    "        \n",
    "Tfidf_vect = TfidfVectorizer(max_features=10000)\n",
    "Tfidf_vect.fit(corpus)\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
    "\n",
    "#the vocabulary that it has learned from the corpus\n",
    "print(Tfidf_vect.vocabulary_)\n",
    "\n",
    "#the vectorized data\n",
    "print(Train_X_Tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A sample of the vocabulary that it has learned from the corpus:**\n",
    "\n",
    "{'installing': 846, 'game': 663, 'struggle': 1615, 'games': 669, 'windows': 1864, 'live': 957, 'bugs': 179}\n",
    "\n",
    "**A sample of the vectorized data:**\n",
    "\n",
    "  (0, 1602)\t0.2521459788527613 <br> \n",
    "  (0, 1536)\t0.44611689308144253 <br> \n",
    "  (0, 1499)\t0.3630663061451349 <br> \n",
    "  (0, 1221)\t0.2521459788527613 <br> \n",
    "  (0, 971)\t0.3097906090161147 <br> \n",
    "  (0, 949)\t0.203737910991826 <br> \n",
    "  (0, 895)\t0.44611689308144253 <br> \n",
    "  (0, 312)\t0.24206473066707476 <br> \n",
    "  (0, 101)\t0.38329154936001714 <br> \n",
    "  (1, 1829)\t0.17313823592091127 <br> \n",
    "  (1, 1782)\t0.2029133806474433 <br> \n",
    "  (1, 1702)\t0.12345297644789534 <br> \n",
    "  (1, 1519)\t0.14399237108946988 <br> \n",
    "  (1, 1476)\t0.21421702520406033 <br> \n",
    "  (1, 1147)\t0.11048831816230155 <br> \n",
    "  \n",
    "Vectorization is being performed in this part to help represent text data in a multidimensional space using float values for the machine to be able to recognize and manipulate. In this example, the TD-IDF algorithm is used performing two steps, first counting the frequency of each token and then calculating the inverse document frequency and compining those together to extract the final vectorized values. \n",
    "\n",
    "In this project two vectorization algorithms are being tested, TF-IDF Vectorizer and Hashing Vectorizer. Both vectorizers are being explained in a latter notebook in more depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------Naive Bayes------------------------\n",
      "\n",
      "Naive Bayes Accuracy Score ->  77.46282394224409\n",
      "\n",
      " [[ 1544   120  6973]\n",
      " [  174   118  8234]\n",
      " [  121    49 52201]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.84      0.18      0.29      8637\n",
      "     Neutral       0.41      0.01      0.03      8526\n",
      "    Negative       0.77      1.00      0.87     52371\n",
      "\n",
      "    accuracy                           0.77     69534\n",
      "   macro avg       0.68      0.40      0.40     69534\n",
      "weighted avg       0.74      0.77      0.70     69534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#[7] Use the Naive Bayes Algorithms to Predict the outcome\n",
    "\n",
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"-----------------------Naive Bayes------------------------\\n\")\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)\n",
    "# Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Test_Y, predictions_NB)\n",
    "print(\"\\n\",cm,\"\\n\")\n",
    "# Printing a classification report of different metrics\n",
    "from sklearn.metrics import classification_report\n",
    "my_tags = ['Positive','Neutral','Negative']\n",
    "print(classification_report(Test_Y, predictions_NB,target_names=my_tags))\n",
    "\n",
    "# Export reports to files for later visualizations\n",
    "report_NB = classification_report(Test_Y, predictions_NB,target_names=my_tags, output_dict=True)\n",
    "report_NB_df = pd.DataFrame(report_NB).transpose()\n",
    "report_NB_df.to_csv(r'NB_report_TFIDFVect.csv', index = True, float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Support Vector Machine CM------------------\n",
      "\n",
      "Accuracy Score ->  82.27485834268128\n",
      "\n",
      " [[ 4993   761  2883]\n",
      " [ 1365  1399  5762]\n",
      " [  880   674 50817]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.69      0.58      0.63      8637\n",
      "     Neutral       0.49      0.16      0.25      8526\n",
      "    Negative       0.85      0.97      0.91     52371\n",
      "\n",
      "    accuracy                           0.82     69534\n",
      "   macro avg       0.68      0.57      0.59     69534\n",
      "weighted avg       0.79      0.82      0.79     69534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#[8] Use the Support Vector Machine Algorithms to Predict the outcome\n",
    "\n",
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"-----------------Support Vector Machine CM------------------\\n\")\n",
    "print(\"Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)\n",
    "cm = confusion_matrix(Test_Y, predictions_SVM)\n",
    "# Making the confusion matrix\n",
    "print(\"\\n\",cm,\"\\n\")\n",
    "# Printing a classification report of different metrics\n",
    "print(classification_report(Test_Y, predictions_SVM,target_names=my_tags))\n",
    "\n",
    "# Export reports to files for later visualizations\n",
    "report_SVM = classification_report(Test_Y, predictions_SVM,target_names=my_tags, output_dict=True)\n",
    "report_SVM_df = pd.DataFrame(report_SVM).transpose()\n",
    "report_SVM_df.to_csv(r'SVM_report_TFIDFVect.csv', index = True, float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the final step classification algorithms are used to Predict the outcome. First of all the training set is fit on the classifier, then the labels are predicted on validation dataset and being stored in the predictions_SVM variable which is then used to calculate the accuracy, the confusion matrix and the classification report.\n",
    "In the very end, the reports are being exported in csv format files in order to be used for visualising the conclusion of the whole project and examine the course of the accuracy scores in the Results & Conclusion notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://nbviewer.jupyter.org/github/panayiotiska/Jupyter-Sentiment-Analysis-Video-games-reviews/blob/master/Vectorization.ipynb\">\n",
    "         <img alt=\"start\" src=\"figures/button_next.jpg\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
