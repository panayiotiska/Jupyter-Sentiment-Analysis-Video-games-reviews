{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr><td>\n",
    "         <a href=\"https://nbviewer.jupyter.org/github/panayiotiska/Jupyter-Sentiment-Analysis-Video-games-reviews/blob/master/SVM_HashingVectorizer_Adjectives%26nouns.ipynb\">\n",
    "         <img alt=\"start\" src=\"figures/button_previous.jpg\" width= 70% height= 70%>\n",
    "    </td><td>\n",
    "        <a href=\"https://nbviewer.jupyter.org/github/panayiotiska/Jupyter-Sentiment-Analysis-Video-games-reviews/blob/master/Index.ipynb\">\n",
    "         <img alt=\"start\" src=\"figures/button_table-of-contents.jpg\" width= 70% height= 70%>\n",
    "    </td><td>\n",
    "         <a href=\"https://nbviewer.jupyter.org/github/panayiotiska/Jupyter-Sentiment-Analysis-Video-games-reviews/blob/master/SVM_HashingVectorizer_Under_Sampling_TomekLinks-Regex.ipynb\">\n",
    "         <img alt=\"start\" src=\"figures/button_next.jpg\" width= 70% height= 70%>\n",
    "    </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "\n",
    "#[1] Importing dataset\n",
    "\n",
    "dataset = pd.read_json(r\"C:\\Users\\Panos\\Desktop\\Dissert\\Code\\Video_Games_5.json\", lines=True, encoding='latin-1')\n",
    "dataset = dataset[['reviewText','overall']]\n",
    "\n",
    "#[2] Reduce number of classes\n",
    "\n",
    "ratings = []\n",
    "for index,entry in enumerate(dataset['overall']):\n",
    "    if entry == 1.0 or entry == 2.0:\n",
    "        ratings.append(-1)\n",
    "    elif entry == 3.0:\n",
    "        ratings.append(0)\n",
    "    elif entry == 4.0 or entry == 5.0:\n",
    "        ratings.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[3] Cleaning the text\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import string\n",
    "import operator\n",
    "import sys\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for i in range(0, len(dataset)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', dataset['reviewText'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    \n",
    "    # Keep the adjectives using nltk\n",
    "    tokens = nltk.word_tokenize(str(review))\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    adjectives_adverbs = [word for word,pos in tags if (pos == 'JJ' or pos == 'IN')]\n",
    "    review_adjectives_adverbs = \" \".join(adjectives_adverbs)\n",
    "    \n",
    "    corpus.append(review_adjectives_adverbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([19837, 122426, 19983])\n"
     ]
    }
   ],
   "source": [
    "#[4] Prepare Train and Test Data sets\n",
    "            \n",
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(corpus,ratings,test_size=0.3)\n",
    "\n",
    "print(Counter(Train_Y).values()) # counts the elements' frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[5] Encoding\n",
    "\n",
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Test_Y = Encoder.fit_transform(Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[6] Word Vectorization\n",
    "        \n",
    "Hashing_vect = HashingVectorizer(alternate_sign=False)\n",
    "Hashing_vect.fit(corpus)\n",
    "Train_X_Hashing = Hashing_vect.transform(Train_X)\n",
    "Test_X_Hashing = Hashing_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Support Vector Machine CM------------------\n",
      "\n",
      "Accuracy Score ->  78.41775246641932\n",
      "\n",
      " [[ 2665     0  5868]\n",
      " [  845     1  7592]\n",
      " [  702     0 51861]] \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.63      0.31      0.42      8533\n",
      "     Neutral       1.00      0.00      0.00      8438\n",
      "    Negative       0.79      0.99      0.88     52563\n",
      "\n",
      "    accuracy                           0.78     69534\n",
      "   macro avg       0.81      0.43      0.43     69534\n",
      "weighted avg       0.80      0.78      0.72     69534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#[8] Use the Support Vector Machine Algorithms to Predict the outcome\n",
    "\n",
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_Hashing,Train_Y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Hashing)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"-----------------Support Vector Machine CM------------------\\n\")\n",
    "print(\"Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)\n",
    "# Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Test_Y, predictions_SVM)\n",
    "print(\"\\n\",cm,\"\\n\")\n",
    "# Printing a classification report of different metrics\n",
    "from sklearn.metrics import classification_report\n",
    "my_tags = ['Positive','Neutral','Negative']\n",
    "print(classification_report(Test_Y, predictions_SVM,target_names=my_tags))\n",
    "\n",
    "# Export reports to files for later visualizations\n",
    "report_SVM = classification_report(Test_Y, predictions_SVM,target_names=my_tags, output_dict=True)\n",
    "report_SVM_df = pd.DataFrame(report_SVM).transpose()\n",
    "report_SVM_df.to_csv(r'SVM_report_HashingVect_Adjectives_Adverbs.csv', index = True, float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://nbviewer.jupyter.org/github/panayiotiska/Jupyter-Sentiment-Analysis-Video-games-reviews/blob/master/SVM_HashingVectorizer_Under_Sampling_TomekLinks-Regex.ipynb\">\n",
    "         <img alt=\"start\" src=\"figures/button_next.jpg\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
